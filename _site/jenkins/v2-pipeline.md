Jenkins 2.0 And The Need For The Pipeline
=========================================

Over the years, Jenkins become the undisputed ruler among continuous integration (CI), delivery and deployment (CD) tools. It, in a way, defined the CI/CD processes we use today. However, no product can stay idle in today's fast evolving market. Everyone needs an active and fast-moving community capable of ever improving to stay ahead of the curve. Jenkins' *release 2.0* proved that it is one of those products. I won't discuss all the new features it comes with but, instead, focus on what is, in my opinion, the most significant change. We'll discuss the *Pipeline* and the need to define CD flows through code.

Before we dive into *Pipeline*, let us take a step back and discuss the reasons that led us to initiate the move away from Freestyle jobs.

The Need for Change
-------------------

Over time, Jenkins, like most other self-hosted CI/CD tools, tends to accumulate a vast number of jobs. Having a lot of them causes quite an increase in maintenance cost. Maintaining ten jobs is easy. It becomes a bit harder (but still bearable) to manage a hundred. When the number of jobs increases to hundreds or even thousands, managing them becomes very tedious and time demanding.

Imagine that we need to change all those jobs from, let’s say, Maven to Gradle. We can choose to start modifying them through the Jenkins UI, but that takes too much time. We can apply changes directly to Jenkins XML files that represent those jobs but that is too complicated and error prone. There are quite a few plugins that can help us to apply changes to multiple jobs at once, but none of them is truly successful (at least among free plugins). They all suffer from one deficiency or another. The problem is not whether we have the tools to perform massive changes to our jobs, but whether jobs are defined in a way that they can be easily maintained.

Besides the sheer number of Jenkins jobs, another critical Jenkins’ pain point is centralization. While having everything in one location provides a lot of benefits (visibility, reporting and so on), it also poses quite a few difficulties. Since the emergence of agile and, especially, DevOps processes, there’s been a massive movement towards self-sufficient teams. Instead of horizontal organization with separate development, testing, infrastructure, operations, and other groups, more and more companies are moving (or already moved) towards teams organized vertically. As a result, having one centralized place that defines all the CD flows becomes a liability and often impedes us from splitting teams vertically based on projects. Members of a team should be able to collaborate effectively without too much reliance on other teams or departments. Translated to CD needs, that means that each team should be able to define the deployment flow of the application they are developing.

Finally, Jenkins, like many other tools, is primarily based on its UI. While that is welcome and needed as a way to get a visual overview through dashboards and reports, it is suboptimal as a way to define the delivery and deployment flow. Jenkins originated in an era when it was fashionable to use UIs for everything. If you worked in this industry long enough, you probably saw the swarm of tools that rely entirely on UIs, drag & drop operations and a lot of forms that should be filled. As a result, we got products that produce artifacts that cannot be easily stored in a code repository and are hard to reason with when anything but simple operations are to be performed. Things changed since then, and now we know that many things (deployment flow being one of them) are much easier to express through code. That can be observed when, for example, we try to define a complex flow through many Jenkins jobs. When deployment complexity requires conditional executions and some kind of a simple intelligence that depends on results of different steps, chained jobs are indeed complicated and, often, impossible to create.

Luckily, all those, and many other deficiencies are now a thing of the past. With the emergence of the *Pipeline Plugin* and many others that were created on top of it, Jenkins entered a new era and proved itself as a dominant player in the CI/CD market. A whole new ecosystem was born, and the door was opened for very exciting possibilities in the future.

What *Jenkins 2.0* brings to the table is the obvious movement towards CD expressed as code. It's not doing it using the big-bang approach. Instead, it chose to maintain backward compatibility with a gentle push towards the future. Due to its enormous market share, it would be unrealistic to expect that all its users should drop years of investment and start fresh. What we see through the new release is a door that just opened and is waiting for you to step through at your pace. That door is the *Pipeline*. Until now, the *Pipeline* was just another plugin. Starting from the *version 2.0*, it is the first class citizen that will define the way you are creating future CD flows.

Continuous Delivery or Deployment Flow with Jenkins
---------------------------------------------------

In all but small projects, tasks that constitute the flow are anything but straightforward and linear. The deployment flow does not consist only of building, testing, and deployment nor it is always defined in a linear fashion.

In many instances, the process is far more complicated. There are many tasks to run, and each of them might produce a failure. In some cases, a failure should only stop the process, while, in others, some additional logic should be executed as part of the after-failure cleanup. We might need to revert to the previous release, rollback the proxy, de-register the service, and so on. Some tasks are run in one of the testing servers while others are run on the production cluster. Some parts of the flow are not linear and depend on task results. Some tasks should be executed in parallel to improve the overall time required to run them. The list goes on and on. The complexity can be, often, very high and cannot be solved by simple chaining of Freestyle jobs. Even in cases when such chaining is possible, the maintenance cost tends to be very high.

On top of that complexity, add conditional logic. In many cases, it is not enough to chain jobs in a linear fashion. Often, we do not want only to create a job that, once it’s finished running, executes some other job. In real-world situations, things are more complicated than that. We might need to run some tasks, and, depending on the result, invoke some other jobs, then run some tasks in parallel, and, finally, execute some jobs only when all others were finished successfully. Those things are easy to accomplish through code while chained Jenkins jobs, created through the UI, pose difficulties to create even a simple conditional logic.

All those needs, and many others, had to be addressed in Jenkins if it was to continue being a dominant CI/CD tool. Fortunately, developers behind the project understood those needs and, as the result, the Jenkins Pipeline become the first class citizen. The future of Jenkins lies in a transition from Freestlyle chained jobs to a single pipeline expressed as code. Modern delivery flows cannot be expressed and easily maintained through UI drag and drop features, nor through chained jobs. They can neither be defined through YML (Yet Another Markup Language) definitions proposed by some of the newer tools (which I’m not going to name). We need to go back to code as a primary way to define not only the applications and services we are developing but almost everything else.
