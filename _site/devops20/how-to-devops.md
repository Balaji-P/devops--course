Shortwhile ago I got the following question.

> I used to be more of a sysadmin and network guy but previously I did also Application support jobs.
I'm about to enter a new Devops project and the project manager is asking me to assess their technology set and see if it does allow or inhibit Continuous Delivery practices? Could you pass me some steps/tips?

I thought that the question is so interesting that it deserves an article by itself. Here's the answer I sent back.

On a very high level, the first thing you need to look at is the company culture. If a company is organized in a slow, bureaucratic way around different horizontal departments, any DevOps attempt will fail. DevOps is all about being fast, automated, and reliable. To accomplish that, you need small (up to ten people) autonomous teams capable of delivering an application or a service from the beginning (requirements) to the end (running and being monitored in production). If there are handoffs, it will fail. If there's too much paperwork, it will fail. If DevOps is a separate department instead being part of a team, it will fail. The last sentence does not mean that there cannot be other teams dedicated to building tools and processes that will help the teams working on development and delivery of different services. Such teams can and should exist. However, it should not be their responsability to deliver a service to production since that would produce handoffs but to help lower the learning curve and build the tooling that can be used by others. In other words, teams are small, self-sufficient, and deliver services from beginning to the end. Others might help those teams but cannot impose solutions nor handoffs.

Once the culture is solved, start looking into software architecture. If it's big, teams cannot be small. Services and applications cannot be passed through the deployment pipeline fast. Deployed services cannot be easily scaled and de-scaled. In other words, if your system is a big monolithic application, start thinking how to break it into smaller pieces. There is a very good reason why microservices, DevOps, and containers became popular at the same time. They depend on each others heavily.

When the first piece of the monolithic application is chipped away and you've got your first microservice, start thinking about the tools you'll use to pass it through the pipeline. In many cases, there is no good reason not to use containers. Benefits are too big to be ignored and, in many cases, without containers you'll realize that having microservices is a too expensive effort and that it creates too much trouble. Today, the only container technology worth talking about is Docker. Once you start using Docker, you'll realize that you need a cluster orchestrator. My choice is to go with Swarm (the new one introduced in Docker 1.12). Kubernetes is also a very good solution (there would be a long discussion why I think the new Swarm is better). With containers and some kind of the cluster orchestration, you'll realize that many things change. Your services/applications should follow "12 factor app" logic. Configuration should be moved from static files to service discovery. Proxies will have to become much more dynamic. Monitoring should also be dynamic. Logging needs to be centralized. The list can go on and on. Tools will be different than what you're used to. They tend to be smaller and more specific. They have to be very dynamic. In a way, microservices philosophy should be applied to tools as well, not only to the services we write.

The point I'm trying to make is that successful DevOps implementation is much more than using a few new tools. It requires changes on all levels. Organization needs to change, people's mindset needs to change, architecture needs to change, tools need to change.

> Do you consider containerization (Docker or Kubernetes) mature enough to be used in production as well - consider that I havent used this technology until now - I just started testing.

Containers are used for 10-15 years (Google is one example). What Docker did is make the usage much easier (working with containers on kernel level is quite difficult). Docker is more than mature enough to be used in production as long as one understands what containers do. I heard, quite a few times, stories how containers are not yet stable in, in most cases, the problem was that they did not fully understand the use cases for containers.

As for orchestrators, all three major players (Swarm, Kubernetes, and Mesos) are used in production by some very large organizations. They are mature and production ready.

The major problem is that big, traditional, enterprise organizations have a tendency to be quite a lot behind and containers might not be a good fit for them since there might be a huge gap.

> One more thought: can CD and Change Management get a long ? I know and feel that the short answer is no but can these be friends somwhow?

The answer to your question depends on the way change management (CM) is implemented. Without any details, I can answer only in general terms.

If CM is done in a proactive fashion, it can easily be part of CD. By proactive, I mean open a ticket to record a new feature, a change to an existing feature, a bug, and so on. Those should be the only manual actions. Do whatever you can do before automation kicks in. The rest of the CM process should be automated. For example, every commit to the repository can trigger a hook that will store the comment into CM tool. A successful execution of a CD flow triggered by a commit that contains CM ID, can close the ticket.

The point is that if you want to put the word "continuous" into the process, you cannot have delays caused by manual actions. In general, that is not a problem at all since the only way to practice CD is to have a reliable set of automated tests that truly validate everything. Without them, you'll have no confidence to deploy to production without human intervention and will end up with CI. On the other hand, if your automation does provide enough confidence to deploy to production, I don't see a reason why it wouldn't provide just as much confidence to close a CM ticket.

I'm not saying that it's wrong to do CI instead of CD or that manual testing and CM should never be used. What I'm trying to say is that we should be clear what each expression means. If you want to do CD, there are no manual actions after a commit (except to press the "deploy" button in case of delivery). If a process is a mixture of manual and automated tasks, then it is CI as long as the flow is run on every commit.  If there are hand-overs and delays caused by them, you can have automated integration, or automated delivery, or automated testing... What you cannot do, in that case, is put the word "continuous" in front.