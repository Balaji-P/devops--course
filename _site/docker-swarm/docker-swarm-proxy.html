<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Integrating Proxy With Docker Swarm (Tour Around Docker 1.12 Series) | vfarcic.github.io</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Integrating Proxy With Docker Swarm (Tour Around Docker 1.12 Series)" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/docker-swarm/docker-swarm-proxy.html" />
<meta property="og:url" content="http://localhost:4000/docker-swarm/docker-swarm-proxy.html" />
<meta property="og:site_name" content="vfarcic.github.io" />
<script type="application/ld+json">
{"url":"http://localhost:4000/docker-swarm/docker-swarm-proxy.html","@type":"WebPage","headline":"Integrating Proxy With Docker Swarm (Tour Around Docker 1.12 Series)","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=d7b0fccce7a840960ab2c608e690e524c171b2d9">
  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="http://localhost:4000/">vfarcic.github.io</a></h1>
      

      <h1 id="integrating-proxy-with-docker-swarm-tour-around-docker-112-series">Integrating Proxy With Docker Swarm (Tour Around Docker 1.12 Series)</h1>

<blockquote>
  <p>This article continues where <a href="https://technologyconversations.com/2016/07/29/docker-swarm-introduction-tour-around-docker-1-12-series/">Docker Swarm Introduction</a> left. I will assume that you have at least a basic knowledge how Swarm in Docker v1.12+ works. If you don’t, please read the previous article first.</p>
</blockquote>

<p>The fact that we can deploy any number of services inside a Swarm cluster does not mean that they are accessible to our users. We already saw that the new Swarm networking made it easy for services to communicate with each other.</p>

<p>Let’s explore how we can utilize it to expose them to the public. We’ll try to integrate a proxy with the Swarm network and further explore benefits version v1.12 brought.</p>

<p>Before we proceed, we need to setup a cluster we’ll use for the examples.</p>

<h2 id="environment-setup">Environment Setup</h2>

<p>The examples that follow assume that you have <a href="https://www.docker.com/products/docker-machine">Docker Machine</a> version v0.8+ that includes <a href="https://www.docker.com/products/docker-engine">Docker Engine</a> v1.12+. The easiest way to get them is through <a href="https://www.docker.com/products/docker-toolbox">Docker Toolbox</a>.</p>

<blockquote>
  <p>If you are a Windows user, please run all the examples from <em>Git Bash</em> (installed through <em>Docker Toolbox</em>).</p>
</blockquote>

<p>I won’t go into details of the environment setup. It is the same as explained in the <a href="https://technologyconversations.com/2016/07/29/docker-swarm-introduction-tour-around-docker-1-12-series/">Docker Swarm Introduction</a> article. We’ll set up three nodes that will form a Swarm cluster.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-machine create -d virtualbox node-1

docker-machine create -d virtualbox node-2

docker-machine create -d virtualbox node-3

eval $(docker-machine env node-1)

docker swarm init \
    --advertise-addr $(docker-machine ip node-1) \
    --listen-addr $(docker-machine ip node-1):2377

TOKEN=$(docker swarm join-token -q worker)

eval $(docker-machine env node-2)

docker swarm join --token $TOKEN $(docker-machine ip node-1):2377

eval $(docker-machine env node-3)

docker swarm join --token $TOKEN $(docker-machine ip node-1):2377
</code></pre></div></div>

<p>Now that we have the Swarm cluster, we can deploy a service.</p>

<p><img src="/img/swarm/swarm-nodes.png" alt="Docker Swarm cluster with three nodes" /></p>

<h2 id="deploying-services-to-the-cluster">Deploying Services To The Cluster</h2>

<p>To experiment the new Docker Swarm networking, we’ll start by creating two networks.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="k">$(</span>docker-machine env node-1<span class="k">)</span>

docker network create <span class="nt">--driver</span> overlay proxy

docker network create <span class="nt">--driver</span> overlay go-demo
</code></pre></div></div>

<p>The first one (<em>proxy</em>) will be used for the communication between the proxy and the services that expose public facing APIs. We’ll use the second (<em>go-demo</em>) for all containers that form the <em>go-demo</em> service. It consists of two containers. It uses MongoDB to store data and <em>vfarcic/go-demo</em> as the back-end with an API.</p>

<p>We’ll start with the database. Since it is not public-facing, there is no need to add it to the proxy. Therefore, we’ll attach it only to the <em>go-demo</em> network.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker service create <span class="nt">--name</span> go-demo-db <span class="se">\</span>
  <span class="nt">--network</span> go-demo <span class="se">\</span>
  mongo
</code></pre></div></div>

<p>With the database up and running, we can deploy the back-end. Since we want our external users to be able to use the API, we should integrate it with the proxy. Therefore, we should attach it to both networks (<em>proxy</em> and <em>go-demo</em>).</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker service create <span class="nt">--name</span> go-demo <span class="se">\</span>
  <span class="nt">-e</span> <span class="nv">DB</span><span class="o">=</span>go-demo-db <span class="se">\</span>
  <span class="nt">--network</span> go-demo <span class="se">\</span>
  <span class="nt">--network</span> proxy <span class="se">\</span>
  vfarcic/go-demo
</code></pre></div></div>

<p><img src="/img/swarm/swarm-nodes-proxy-sdn.png" alt="Docker Swarm cluster with three nodes, two networks and a few containers" /></p>

<p>Now both containers are running somewhere inside the cluster and are able to communicate with each other through the <em>go-demo</em> network. Let’s bring the proxy into the mix. We’ll use <a href="http://www.haproxy.org/">HAProxy</a>. The principles we’ll explore are the same no matter which one will be your choice.</p>

<p>Please note that we did not specify ports. That means the neither containers are accessible from outside the <em>go-demo</em> network.</p>

<h2 id="setting-up-a-proxy-service">Setting Up a Proxy Service</h2>

<p>We can implement the proxy in a couple of ways. One would be to create a new image based on <em><a href="https://hub.docker.com/_/haproxy/">HAProxy</a></em> and include configuration files inside it. That approach would be a good one if the number of different services is relatively static. Otherwise, we’d need to create a new image with a new configuration every time there is a new service (not a new release).</p>

<p>The second approach would be to expose a volume. That way, when needed, we could modify the configuration file instead building a whole new image. However, that has downsides as well. When deploying to a cluster, we should avoid using volumes whenever that’s not necessary. As you’ll see soon, a proxy is one of those that do not require a volume. As a side note, <code class="highlighter-rouge">--volume</code> has been replaced with the <code class="highlighter-rouge">docker service</code> argument <code class="highlighter-rouge">--mount</code>.</p>

<p>The third option is to use one of the proxies designed to work with Docker Swarm. In this case, we’ll use <em><a href="https://hub.docker.com/r/docker-flow/docker-flow-proxy/">docker-flow/docker-flow-proxy</a></em> container, created from the <em><a href="https://github.com/docker-flow/docker-flow-proxy">Docker Flow: Proxy</a></em> project. It is based on HAProxy with additional features that allow us to reconfigure it by sending HTTP requests.</p>

<p>Let’s give it a spin.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker service create <span class="nt">--name</span> proxy <span class="se">\</span>
    <span class="nt">-p</span> 80:80 <span class="se">\</span>
    <span class="nt">-p</span> 443:443 <span class="se">\</span>
    <span class="nt">-p</span> 8080:8080 <span class="se">\</span>
    <span class="nt">--network</span> proxy <span class="se">\</span>
    <span class="nt">-e</span> <span class="nv">MODE</span><span class="o">=</span>swarm <span class="se">\</span>
    dockerflow/docker-flow-proxy
</code></pre></div></div>

<p>We opened ports <em>80</em> and <em>443</em> that will serve Internet traffic (<em>HTTP</em> and <em>HTTPS</em>). The third port is <em>8080</em>. We’ll use it to send configuration requests to the proxy. Further on, we specified that it should belong to the <em>proxy</em> network. That way, since <em>go-demo</em> is also attached to the same network, the proxy can access it through the SDN.</p>

<p>Through the proxy we just run we can observe one of the cool features of the network routing mesh. It does not matter on which server the proxy is running. We can send a request to any of the nodes and Docker network will make sure that it is redirected to one of the proxies.</p>

<p>The last argument is the environment variable <em>MODE</em> that tells the proxy that containers will be deployed to a Swarm cluster. Please consult the project <a href="https://github.com/docker-flow/docker-flow-proxy">README</a> for other combinations.</p>

<p><img src="/img/swarm/swarm-nodes-proxy.png" alt="Docker Swarm cluster with the proxy service" /></p>

<blockquote>
  <p>Please note that the proxy, even though it is running inside one of the nodes, is placed outside to better illustrate the logical separation.</p>
</blockquote>

<p>Before we move on, let’s confirm that the proxy is running.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker service ps proxy
</code></pre></div></div>

<p>We can proceed if the <em>Last state</em> is <em>Running</em>. Otherwise, please wait until the service is up and running.</p>

<p>Now that the proxy is deployed, we should let it know about the existence of the <em>go-demo</em> service.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="s2">"</span><span class="k">$(</span>docker-machine ip node-1<span class="k">)</span><span class="s2">:8080/v1/docker-flow-proxy/reconfigure?serviceName=go-demo&amp;servicePath=/demo&amp;port=8080"</span>
</code></pre></div></div>

<p>The request was sent to <em>reconfigure</em> the proxy specifying the service name (<em>go-demo</em>), URL path of the API (<em>/demo</em>), and the internal port of the service (<em>8080</em>). From now on, all the requests to the proxy with the path that starts with <em>/demo</em> will be redirected to the <em>go-demo</em> service.</p>

<p>We can test that the proxy indeed works as expected by sending an HTTP request.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-i</span> <span class="k">$(</span>docker-machine ip node-1<span class="k">)</span>/demo/hello
</code></pre></div></div>

<p>The output of the <code class="highlighter-rouge">curl</code> command is as follows.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HTTP/1.1 200 OK
Date: Mon, 18 Jul 2016 23:11:31 GMT
Content-Length: 14
Content-Type: text/plain; charset=utf-8

hello, world!
</code></pre></div></div>

<p>The proxy works! It responded with the HTTP status <em>200</em> and returned the API response <em>hello, world!</em>.</p>

<p>Please note that it does not matter to which node we send the request. Since Docker networking (routing mesh) takes care of load balancing, we can hit any of the servers. As an example, let’s send the same request but, this time, to the <em>node-3</em>.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-i</span> <span class="k">$(</span>docker-machine ip node-3<span class="k">)</span>/demo/hello
</code></pre></div></div>

<p>The result is still the same.</p>

<p>Let’s explore the configuration generated by the proxy.</p>

<h2 id="proxy-configuration">Proxy Configuration</h2>

<p>If you choose to roll-up your own proxy solution, it might be useful to understand how to configure the proxy and leverage new Docker networking features.</p>

<p>Let’s start by examining the configuration <em><a href="https://github.com/docker-flow/docker-flow-proxy">Docker Flow: Proxy</a></em> created for us. We can do that by entering the running container to take a sneak peek at the <em>/cfg/haproxy.cfg</em> file. The problem is that finding a container run by Docker Swarm is a bit tricky. For example, if we deployed it with Docker Compose, the container name would be predictable. It would use <PROJECT>_<SERVICE>_<INDEX> format. The `docker service` command runs containers with hashed names. The *docker-flow-proxy* created on my laptop has the name *proxy.1.e07jvhdb9e6s76mr9ol41u4sn*. Therefore, to get inside a running container deployed with Docker Swarm, we need to use a filter with, for example, image name.</INDEX></SERVICE></PROJECT></p>

<p>First, we need to find out on which node the proxy is running.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker service ps proxy
</code></pre></div></div>

<p>Please note the value of the <em>node</em> column and make sure that it is used in the command that follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="k">$(</span>docker-machine env node-1<span class="k">)</span> <span class="c"># Change node-1 with the node value previously obtained</span>
</code></pre></div></div>

<p>The command that will output configuration of the proxy is as follows.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-it</span> <span class="se">\</span>
    <span class="k">$(</span>docker ps <span class="nt">-q</span> <span class="nt">--filter</span> <span class="s2">"ancestor=dockerflow/docker-flow-proxy"</span><span class="k">)</span> <span class="se">\</span>
    <span class="nb">cat</span> /cfg/haproxy.cfg
</code></pre></div></div>

<p>The important part of the configuration is as follows.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>frontend services
    bind *:80
    bind *:443
    option http-server-close

    acl url_go-demo path_beg /demo
    use_backend go-demo-be if url_go-demo

backend go-demo-be
    server go-demo go-demo:8080
</code></pre></div></div>

<p>The first part (<code class="highlighter-rouge">frontend</code>) should be familiar to those who used HAProxy. It accepts requests on ports <code class="highlighter-rouge">80</code> (<em>HTTP</em>) and <code class="highlighter-rouge">443</code> (<em>HTTPS</em>). If the path starts with <code class="highlighter-rouge">/demo</code>, it will be redirected to the <code class="highlighter-rouge">backend go-demo-be</code>. Inside it, requests are sent to the address <code class="highlighter-rouge">go-demo</code> on the port <code class="highlighter-rouge">8080</code>. The address is the same as the name of the service we deployed. Since <code class="highlighter-rouge">go-demo</code> belongs to the same network as the proxy, Docker will make sure that the request is redirected to the destination container. Neat, isn’t it? There is no need, anymore, to specify IPs and external ports.</p>

<p>The next question is how to do load balancing. How should we specify that the proxy should, for example, perform round-robin across all instances?</p>

<h2 id="load-balancing">Load Balancing</h2>

<p>Before we start load balancing explanation, let’s create a few more instances of the <em>go-demo</em> service.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="k">$(</span>docker-machine env node-1<span class="k">)</span>

docker service scale go-demo<span class="o">=</span>5
</code></pre></div></div>

<p>Within a few moments, five instances of the <em>go-demo</em> service will be running.</p>

<p><img src="/img/swarm/swarm-nodes-proxy-scaled.png" alt="Docker Swarm cluster scaled go-demo service and the proxy instance" /></p>

<p>What should we do to make the proxy balance requests across all instances? The answer is nothing. No action is necessary on our part.</p>

<p>Normally, if we wouldn’t leverage Docker Swarm features, we would have something similar to the following configuration mock-up.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>backend go-demo-be
    server instance_1 &lt;INSTANCE_1_IP&gt;:&lt;INSTANCE_1_PORT&gt;
    server instance_2 &lt;INSTANCE_2_IP&gt;:&lt;INSTANCE_2_PORT&gt;
    server instance_3 &lt;INSTANCE_3_IP&gt;:&lt;INSTANCE_3_PORT&gt;
    server instance_4 &lt;INSTANCE_4_IP&gt;:&lt;INSTANCE_4_PORT&gt;
    server instance_5 &lt;INSTANCE_5_IP&gt;:&lt;INSTANCE_5_PORT&gt;
</code></pre></div></div>

<p>However, with the new Docker networking inside a Swarm cluster, that is not necessary. It only introduces complications that require us to monitor instances and update the proxy every time a new replica is added or removed.</p>

<p>Docker will do load balancing for us. To be more precise, when the proxy redirects a request to <code class="highlighter-rouge">go-demo</code>, it is sent to Docker networking which, in turn, performs load balancing across all replicas (instances) of the service. The implication of this approach is that proxy is in charge of redirection from port <em>80</em> (or <em>443</em>) to the correct service inside the network, and Docker does the rest.</p>

<p>Feel free to make requests to the service and inspect logs of one of the replicas. You’ll see that, approximately, one fifth of the requests is sent to it.</p>

<h2 id="final-words">Final Words</h2>

<p>Docker networking introduced with the new Swarm included in Docker 1.12+ opens a door for quite a few new opportunities. Internal communication between containers and load balancing are only a few. Configuring public facing proxies became easier than ever. We have to make sure that all services that expose a public facing API are plugged into the same network as the proxy. From there on, all we have to do is configure it to redirect all requests to the name of the destination service. That will result in requests traveling from the proxy to Docker network which, in turn, will perform load balancing across all instances.</p>

<p>The question that might arise is whether this approach is efficient. After all, we introduced a new layer. While in the past we’d have only a proxy and a service, now we have Docker networking with a load balancer in between. The answer is that overhead of such an approach is minimal. Docker uses <a href="http://www.linuxvirtualserver.org/software/ipvs.html">Linux IPVS</a> for load balancing. It’s been in the Linux kernel for more than fifteen years and proved to be one of the most efficient ways to load balance requests. Actually, it is much faster than <em>nginx</em> or <em>HAProxy</em>.</p>

<p>The next question is whether we need a proxy. We do. IPVS used by Docker will not do much more than load balancing. We still need a proxy that will accept requests on ports <em>80</em> and <em>443</em> and, depending on their paths, redirect them to one service or another. On top of that, we might use it to perform other tasks like SSL handshake, authentication, and so on.</p>

<p>What are the downsides? The first one that comes to my mind are sticky sessions. If you expect the same user to send requests to the same instance, this approach will not work. A separate question is whether we should implement sticky sessions inside our services or as a separate entity. I’ll leave that discussion for one of the next articles. Just keep in mind that sticky sessions will not work with this type of load balancing.</p>

<p>How about advantages? You already saw that simplicity is one of them. There’s no need to reconfigure your proxy every time a new replica is deployed. As a result, the whole process is greatly simplified. Since we don’t need the list of all IPs and ports of all instances, there is no need for tools like <a href="https://github.com/gliderlabs/registrator">Registrator</a> and <a href="https://github.com/hashicorp/consul-template">Consul Template</a>. In the past, one of the possible solutions was to use Registrator to monitor Docker events and store IPs and ports in a key-value store (e.g. <a href="https://www.consul.io/">Consul</a>). Once information is stored, we would use Consul Template to recreate proxy configuration. There we many projects that simplified the process (one of them being the old version of the <a href="https://github.com/docker-flow/docker-flow-proxy">Docker Flow: Proxy</a>). However, with Docker Swarm and networking, the process just got simpler.</p>

<h2 id="to-docker-flow-proxy-or-not-to-docker-flow-proxy">To <em>Docker Flow: Proxy</em> Or Not To <em>Docker Flow: Proxy</em></h2>

<p>I showed you how to configure HAProxy using <a href="https://github.com/docker-flow/docker-flow-proxy">Docker Flow: Proxy</a> project. It contains HAProxy with an additional API that allows it to reconfigure the proxy with a simple HTTP request. It removes the need for manual configuration or templates.</p>

<p>On the other hand, rolling up your own solution became easier than ever. With the few pointers from this article, you should have no problem creating <em>nginx</em> or <em>HAProxy</em> configuration yourself.</p>

<p>My suggestion is to give <a href="https://github.com/docker-flow/docker-flow-proxy">Docker Flow: Proxy</a> a try before you make a decision. In either case, new Docker Swarm networking features are impressive and provide building blocks for more to come.</p>

<h2 id="what-now">What Now?</h2>

<p>That concludes the exploration of some of the new Swarm and networking features we got with Docker v1.12. In particular, we explored those related to public facing proxies.</p>

<p>Is this everything there is to know to run a Swarm cluster successfully? Not even close! What we explored by now (in this and the previous article) is only the beginning. There are quite a few questions waiting to be answered. What happened to Docker Compose? How do we deploy new releases without downtime? Are there any additional tools we should use?</p>

<p>I’ll try to give answers to those and quite a few other questions in future articles. The next one will be dedicated to <em>Distributed Application Bundles</em>.</p>


      
      <div class="footer border-top border-gray-light mt-5 pt-3 text-right text-gray">
        This site is open source. <a href="https://github.com/vfarcic/vfarcic.github.io/edit/gh-pages/docker-swarm/docker-swarm-proxy.md">Improve this page</a>.
      </div>
      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
    
  </body>
</html>
