<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hands-On Time | vfarcic.github.io</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hands-On Time" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/devops23/svc-demo.html" />
<meta property="og:url" content="http://localhost:4000/devops23/svc-demo.html" />
<meta property="og:site_name" content="vfarcic.github.io" />
<script type="application/ld+json">
{"url":"http://localhost:4000/devops23/svc-demo.html","@type":"WebPage","headline":"Hands-On Time","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=d7b0fccce7a840960ab2c608e690e524c171b2d9">
  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="http://localhost:4000/">vfarcic.github.io</a></h1>
      

      <h2 id="hands-on-time">Hands-On Time</h2>

<hr />

<h1 id="using-services-to-enable-communication-between-pods">Using Services To Enable Communication Between Pods</h1>

<h2 id="exposing-ports">Exposing Ports</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat </span>svc/go-demo-2-rs.yml

kubectl create <span class="nt">-f</span> svc/go-demo-2-rs.yml

kubectl get <span class="nt">-f</span> svc/go-demo-2-rs.yml

<span class="c"># If minikube</span>
kubectl expose rs go-demo-2 <span class="nt">--name</span><span class="o">=</span>go-demo-2-svc <span class="nt">--target-port</span><span class="o">=</span>28017 <span class="se">\</span>
    <span class="nt">--type</span><span class="o">=</span>NodePort

<span class="c"># If EKS or GKE</span>
kubectl expose rs go-demo-2 <span class="nt">--name</span><span class="o">=</span>go-demo-2-svc <span class="nt">--target-port</span><span class="o">=</span>28017 <span class="se">\</span>
    <span class="nt">--type</span><span class="o">=</span>LoadBalancer
</code></pre></div></div>

<p>Note:
Looking at the yml file we customized the command and the arguments so that MongoDB exposes the REST interface. Those additions are needed so that we can test that the database is accessible through the Service. We can use the kubectl expose command to expose a resource as a new Kubernetes Service. That resource can be a Deployment, another Service, a ReplicaSet, a ReplicationController, or a Pod. We’ll expose the ReplicaSet since it is already running in the cluster. In this exercise we show how to create two different services.</p>
<ul>
  <li>We recreated the <em>go-demo-2</em> ReplicaSet</li>
  <li>We exposed the port <code class="highlighter-rouge">28017</code> of the ReplicaSet <code class="highlighter-rouge">go-demo-2</code> using imperative process</li>
  <li><code class="highlighter-rouge">NodePort</code> type exposes the port on all of the worker nodes of the cluster</li>
  <li><code class="highlighter-rouge">LoadBalancer</code> acts as <code class="highlighter-rouge">NodePort</code>, but it also creates an external load balancer</li>
</ul>

<!-- .slide: data-background="img/seq_svc_ch05.png" data-background-size="contain" -->

<p>Note:</p>
<ol>
  <li>Kubernetes client (kubectl) sent a request to the API server requesting the creation of the Service based on Pods created through the go-demo-2 ReplicaSet.</li>
  <li>Endpoint controller is watching the API server for new service events. It detected that there is a new Service object.</li>
  <li>Endpoint controller created endpoint objects with the same name as the Service, and it used Service selector to identify endpoints (in this case the IP and the port of go-demo-2 Pods).</li>
  <li>kube-proxy is watching for service and endpoint objects. It detected that there is a new Service and a new endpoint object.</li>
  <li>kube-proxy added iptables rules which capture traffic to the Service port and redirect it to endpoints. For each endpoint object, it adds iptables rule which selects a Pod.</li>
  <li>The kube-dns add-on is watching for Service. It detected that there is a new service.</li>
  <li>The kube-dns added db’s record to the dns</li>
</ol>

<!-- .slide: data-background="img/comp_svc_ch05.png" data-background-size="contain" -->

<h2 id="exposing-ports-1">Exposing Ports</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl describe svc go-demo-2-svc

<span class="c"># If minikube</span>
<span class="nv">PORT</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-svc <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].nodePort}"</span><span class="k">)</span>

<span class="c"># If EKS or GKE</span>
<span class="nv">PORT</span><span class="o">=</span>28017
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We described the newly created Service</li>
  <li>We retrieved the port through which we can access the new Service</li>
  <li>EKS and GKE opened the same port in <code class="highlighter-rouge">loadBalancer</code> as the target port, and it forwards requests to the randomly generated NodePort</li>
</ul>

<h2 id="exposing-ports-2">Exposing Ports</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If minikube</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>minikube ip<span class="k">)</span>

<span class="c"># If EKS</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-svc <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].hostname}"</span><span class="k">)</span>

<span class="c"># If GKE</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-svc <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].ip}"</span><span class="k">)</span>
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We retrieved the IP/address through which we can access the new Service</li>
  <li>minikube’s address is the IP of the VM</li>
  <li>EKS’ address is the address of the ELB</li>
  <li>GKE’ address is the IP of the ELB</li>
</ul>

<h2 id="exposing-ports-3">Exposing Ports</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>open <span class="s2">"http://</span><span class="nv">$IP</span><span class="s2">:</span><span class="nv">$PORT</span><span class="s2">"</span>

kubectl delete svc go-demo-2-svc
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We validated that MongoUI is accessible through the Service</li>
  <li>We deleted the Service</li>
</ul>

<!-- .slide: data-background="img/svc-expose-rs.png" data-background-size="contain" -->

<h2 id="declarative-syntax">Declarative Syntax</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If minikube</span>
<span class="nb">cat </span>svc/go-demo-2-svc.yml

<span class="c"># If EKS or GKE</span>
<span class="nb">cat </span>svc/go-demo-2-svc-lb.yml

<span class="c"># If minikube</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2-svc.yml

<span class="c"># If EKS or GKE</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2-svc-lb.yml

kubectl get <span class="nt">-f</span> svc/go-demo-2-svc.yml
</code></pre></div></div>

<p>Note:
 When we cat the file we see the selector is used by the Service to know which Pods should receive requests. It works in the same way as ReplicaSet selectors. In this case, we defined that the service should forward requests to Pods with labels type set to backend and service set to go-demo. Those two labels are set in the Pods spec of the ReplicaSet.</p>
<ul>
  <li>We created a Service using declarative syntax (YAML)</li>
  <li>We retrieved the basic info about the newly created Service</li>
  <li>The difference between minikube and EKS/GKE Service is in <code class="highlighter-rouge">type</code> (<code class="highlighter-rouge">NodePort</code> or <code class="highlighter-rouge">LoadBalancer</code>)</li>
</ul>

<h2 id="declarative-syntax-1">Declarative Syntax</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If EKS</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2 <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].hostname}"</span><span class="k">)</span>

<span class="c"># If GKE</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2 <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].ip}"</span><span class="k">)</span>

<span class="c"># If minikube</span>
<span class="nv">PORT</span><span class="o">=</span>30001

open <span class="s2">"http://</span><span class="nv">$IP</span><span class="s2">:</span><span class="nv">$PORT</span><span class="s2">"</span>
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We retrieved the IP/address and the port</li>
  <li>minikube’s IP is the same as it was, EKS and GKE created a new ELB with a new address</li>
  <li>EKS and GKE open the same port in ELB as target port, so it’s left unchanged</li>
</ul>

<!-- .slide: data-background="img/svc-hard-coded-port.png" data-background-size="contain" -->

<h2 id="declarative-syntax-2">Declarative Syntax</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete <span class="nt">-f</span> svc/go-demo-2-svc.yml

kubectl delete <span class="nt">-f</span> svc/go-demo-2-rs.yml
</code></pre></div></div>

<p>Note:
Now we can clean up the cluster by deleting the ReplicaSet and Service</p>

<h2 id="communication-through-services">Communication Through Services</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat </span>svc/go-demo-2-db-rs.yml

kubectl create <span class="nt">-f</span> svc/go-demo-2-db-rs.yml

<span class="nb">cat </span>svc/go-demo-2-db-svc.yml

kubectl create <span class="nt">-f</span> svc/go-demo-2-db-svc.yml

<span class="nb">cat </span>svc/go-demo-2-api-rs.yml

kubectl create <span class="nt">-f</span> svc/go-demo-2-api-rs.yml
</code></pre></div></div>

<p>Note:
When we at the <code class="highlighter-rouge">go-demo-2-api-rs</code> file:
The number of replicas is set to 3. That solves one of the main problems we had with the previous ReplicaSets that defined Pods with both containers. Now the number of replicas can differ, and we have one Pod for the database, and three for the backend API. The type label is set to api so that both the ReplicaSet and the (soon to come) Service can distinguish the Pods from those created for the database. We have the environment variable DB set to go-demo-2-db. The code behind the vfarcic/ go-demo-2 image is written in a way that the connection to the database is established by reading that variable. In this case, we can say that it will try to connect to the database running on the DNS go-demo-2-db. If you go back to the database Service definition, you’ll notice that its name is go-demo-2-db as well. If everything works correctly, we should expect that the DNS was created with the Service and that it’ll forward requests to the database. The <code class="highlighter-rouge">readinessProbe</code> has the same fields as the <code class="highlighter-rouge">livenessProbe</code>. We used the same values for both, except for the <code class="highlighter-rouge">periodSeconds</code>, where instead of relying on the default value of 10, we set it to 1. While livenessProbe is used to determine whether a Pod is alive or it should be replaced by a new one, the readinessProbe is used by the iptables. A Pod that does not pass the readinessProbe will be excluded and will not receive requests. In theory, Requests might be still sent to a faulty Pod, between two iterations. Still, such requests will be small in number since the iptables will change as soon as the next probe responds with HTTP code less than 200, or equal or greater than 400.</p>

<ul>
  <li>We created a ReplicaSet with a DB</li>
  <li>We created a Service type <code class="highlighter-rouge">ClusterIP</code> for the DB</li>
  <li>We created a ReplicaSet with the API</li>
</ul>

<h2 id="communication-through-services-1">Communication Through Services</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If minikube</span>
<span class="nb">cat </span>svc/go-demo-2-api-svc.yml

<span class="c"># If EKS or GKE</span>
<span class="nb">cat </span>svc/go-demo-2-api-svc-lb.yml

<span class="c"># If minikube</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2-api-svc.yml

<span class="c"># If EKS or GKE</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2-api-svc-lb.yml

kubectl get all
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We created a Service for the API</li>
  <li>We listed all the resources we created</li>
  <li>For minikube we used Service type <code class="highlighter-rouge">NodePort</code></li>
  <li>For EKS or GKE we used Service type <code class="highlighter-rouge">LoadBalancer</code></li>
</ul>

<h2 id="communication-through-services-2">Communication Through Services</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If EKS</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].hostname}"</span><span class="k">)</span>

<span class="c"># If GKE</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].ip}"</span><span class="k">)</span>

<span class="c"># If minikube</span>
<span class="nv">PORT</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].nodePort}"</span><span class="k">)</span>

<span class="c"># If EKS or GKE</span>
<span class="nv">PORT</span><span class="o">=</span>8080

curl <span class="nt">-i</span> <span class="s2">"http://</span><span class="nv">$IP</span><span class="s2">:</span><span class="nv">$PORT</span><span class="s2">/demo/hello"</span>
</code></pre></div></div>

<p>Note:
Before running <code class="highlighter-rouge">kubectl get svc...</code> it is worth mentioning that the code behind the vfarcic/ go-demo-2 image is designed to fail if it cannot connect to the database. The fact that the three replicas of the go-demo-2-api Pod are running means that the communication is established.</p>
<ul>
  <li>We retrieved API Service address and port</li>
  <li>We sent a request to the API to confirm that it is accessible</li>
  <li>EKS or GKE created a new ELB so the IP changed</li>
  <li>The Service in minikube exposed a new random port</li>
  <li>The port of the Service in EKS or GKE is the same as the target port</li>
</ul>

<h2 id="communication-through-services-3">Communication Through Services</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete <span class="nt">-f</span> svc/go-demo-2-db-rs.yml

kubectl delete <span class="nt">-f</span> svc/go-demo-2-db-svc.yml

kubectl delete <span class="nt">-f</span> svc/go-demo-2-api-rs.yml

kubectl delete <span class="nt">-f</span> svc/go-demo-2-api-svc.yml
</code></pre></div></div>

<p>Note:
Now we are going to cleanup the cluster by deleting everything created from the various yml files.</p>

<h2 id="multiple-resources-in-yaml">Multiple Resources In YAML</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If minikube</span>
<span class="nb">cat </span>svc/go-demo-2.yml

<span class="c"># If EKS or GKE</span>
<span class="nb">cat </span>svc/go-demo-2-lb.yml

<span class="c"># If minikube</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2.yml

<span class="c"># If EKS or GKE</span>
kubectl create <span class="nt">-f</span> svc/go-demo-2-lb.yml

kubectl get <span class="nt">-f</span> svc/go-demo-2.yml
</code></pre></div></div>

<p>Note:
The vfarcic/ go-demo-2 and mongo images form the same stack. They work together and having four YAML definitions is confusing. It would get even more confusing later on since we are going to add more objects to the stack. Things would be much simpler and easier if we would move all the objects we created thus far into a single YAML definition. Fortunately, that is very easy to accomplish. In the following example we created all the resources from a single YAML file. Afterwards we will confirm all the resources are created.</p>

<h2 id="multiple-resources-in-yaml-1">Multiple Resources In YAML</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># If EKS</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].hostname}"</span><span class="k">)</span>

<span class="c"># If GKE</span>
<span class="nv">IP</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[0].ip}"</span><span class="k">)</span>

<span class="c"># If minikube</span>
<span class="nv">PORT</span><span class="o">=</span><span class="k">$(</span>kubectl get svc go-demo-2-api <span class="se">\</span>
    <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].nodePort}"</span><span class="k">)</span>
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We retrieved the IP and the port of the API Service</li>
  <li>EKS or GKE created a new ELB so the IP changed</li>
  <li>The Service in minikube exposed a new random port</li>
</ul>

<h2 id="multiple-resources-in-yaml-2">Multiple Resources In YAML</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl <span class="nt">-i</span> <span class="s2">"http://</span><span class="nv">$IP</span><span class="s2">:</span><span class="nv">$PORT</span><span class="s2">/demo/hello"</span>

<span class="nv">POD_NAME</span><span class="o">=</span><span class="k">$(</span>kubectl get pod <span class="nt">--no-headers</span> <span class="se">\</span>
    <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span>NAME:.metadata.name <span class="se">\</span>
    <span class="nt">-l</span> <span class="nb">type</span><span class="o">=</span>api,service<span class="o">=</span>go-demo-2 | tail <span class="nt">-1</span><span class="k">)</span>

kubectl <span class="nb">exec</span> <span class="nv">$POD_NAME</span> env
</code></pre></div></div>

<p>Note:</p>
<ul>
  <li>We are going to send a request to confirm that the API is accessible through the Service</li>
  <li>We going to list the environment variables in one of the Pods to display Service-specific info
The first five variables are using the Docker format. If you already worked with Docker networking, you should be familiar with them. At least, if you’re familiar with the way Swarm (standalone) and Docker Compose operate. Later version of Swarm (Mode) still generate the environment variables but they are mostly abandoned by the users in flavor of DNSes.
    <ol>
      <li>GO_DEMO_2_DB_PORT = tcp:// 10.0.0.250: 27017</li>
      <li>GO_DEMO_2_DB_PORT_27017_TCP_ADDR = 10.0.0.250</li>
      <li>GO_DEMO_2_DB_PORT_27017_TCP_PROTO = tcp</li>
      <li>GO_DEMO_2_DB_PORT_27017_TCP_PORT = 27017</li>
      <li>GO_DEMO_2_DB_PORT_27017_TCP = tcp:// 10.0.0.250: 27017</li>
      <li>GO_DEMO_2_DB_SERVICE_HOST = 10.0.0.250</li>
      <li>GO_DEMO_2_DB_SERVICE_PORT = 27017</li>
    </ol>
  </li>
</ul>

<p>The last two environment variables are Kubernetes specific and follow the <code class="highlighter-rouge">[SERVICE_NAME]SERVICE_HOST </code>and <code class="highlighter-rouge">[SERVICE_NAME]_SERIVCE_PORT</code> format (service name is upper-cased). No matter which set of environment variables</p>

<!-- .slide: data-background="img/flow_svc_ch05.png" data-background-size="contain" -->

<p>Note:</p>
<ol>
  <li>When the api container go-demo-2 tries to connect with the go-demo-2-db Service, it looks at the nameserver configured in /etc/ resolv.conf. kubelet configured the nameserver with the kube-dns Service IP (10.96.0.10) during the Pod scheduling process.</li>
  <li>The container queries the DNS server listening to port 53. go-demo-2-db DNS gets resolved to the service IP 10.0.0.19. This DNS record was added by kube-dns during the service creation process.</li>
  <li>The container uses the service IP which forwards requests through the iptables rules. They were added by kube-proxy during Service and Endpoint creation process.</li>
  <li>Since we only have one replica of the go-demo-2-db Pod, iptables forwards requests to just one endpoint. If we had multiple replicas, iptables would act as a load balancer and forward requests randomly among Endpoints of the Service.</li>
</ol>

<h2 id="services">Services?</h2>

<hr />

<ul>
  <li>Communication between Pods<!-- .element: class="fragment" --></li>
  <li>Communication from outside the cluster<!-- .element: class="fragment" --></li>
</ul>

<!-- .slide: data-background="img/svc-components.png" data-background-size="contain" -->

<h2 id="what-now">What Now?</h2>

<hr />

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl delete <span class="nt">-f</span> svc/go-demo-2.yml
</code></pre></div></div>


      
      <div class="footer border-top border-gray-light mt-5 pt-3 text-right text-gray">
        This site is open source. <a href="https://github.com/vfarcic/vfarcic.github.io/edit/gh-pages/devops23/svc-demo.md">Improve this page</a>.
      </div>
      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
    
  </body>
</html>
